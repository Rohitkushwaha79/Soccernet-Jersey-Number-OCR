{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"ca82568e-5725-4d51-a2d6-10e6429274fc","_uuid":"a4e47c6f-74a5-4aa2-baee-042563b90210","collapsed":false,"execution":{"iopub.execute_input":"2024-04-11T09:35:09.466534Z","iopub.status.busy":"2024-04-11T09:35:09.465905Z","iopub.status.idle":"2024-04-11T09:35:09.883839Z","shell.execute_reply":"2024-04-11T09:35:09.882898Z","shell.execute_reply.started":"2024-04-11T09:35:09.466498Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"source":["# SoccerNet Jersey Extraction Dataset Creation\n","\n","## Introduction\n","\n","Welcome to my SoccerNet Jersey Extraction Dataset Creation notebook! Here, I'll be focusing on creating that consist of jersey exract from SoccerNet jersey number recognition dataset. The SoccerNet dataset provides a large collection player frames from soccer match videos, making it an ideal resource for training computer vision models to recognize and extract jersey numbers from player frames.\n","\n","## Goals\n","\n","- **Dataset Creation**: Generate a dataset containing jersey extract of soccer players and their corresponding jersey numbers as a label.\n","- **Data Preprocessing**: Perform necessary preprocessing steps such as image resizing, cropping, and normalization etc. .\n","- **Dataset Storage**: Save the preprocessed dataset in an appropriate format for easy access and future use.\n","\n","## Note\n","\n","Ensure that you have access to the SoccerNet dataset or have downloaded the required data for this notebook to run successfully.\n","\n","Let's get started!\n"]},{"cell_type":"markdown","metadata":{},"source":["### Package Installation\n","- **Ultralytics**: This package provides utilities and tools for working with computer vision models, including object detection, image classification, and more.\n","- **natsort**: This package offers human-friendly sorting of lists and arrays."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T09:35:09.885926Z","iopub.status.busy":"2024-04-11T09:35:09.885599Z","iopub.status.idle":"2024-04-11T09:35:41.315839Z","shell.execute_reply":"2024-04-11T09:35:41.314649Z","shell.execute_reply.started":"2024-04-11T09:35:09.885898Z"},"trusted":true},"outputs":[],"source":["!pip install ultralytics\n","!pip install natsort"]},{"cell_type":"markdown","metadata":{},"source":["### Importing Necessary Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import itertools\n","import time\n","from ultralytics import YOLO\n","from natsort import natsorted\n","import concurrent.futures"]},{"cell_type":"markdown","metadata":{},"source":["### Loading the YOLOv8 Pose Model\n","\n","Before proceeding, we need to load the YOLOv8 Pose model. This model will be used for detecting poses and keypoints in the soccer player images."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T09:35:41.318225Z","iopub.status.busy":"2024-04-11T09:35:41.317884Z","iopub.status.idle":"2024-04-11T09:35:49.265058Z","shell.execute_reply":"2024-04-11T09:35:49.263851Z","shell.execute_reply.started":"2024-04-11T09:35:41.318195Z"},"trusted":true},"outputs":[],"source":["model = YOLO(\"/kaggle/input/yolov8-pose-models/models/yolov8m-pose.pt\")"]},{"cell_type":"markdown","metadata":{},"source":["# Demonstrating Dataset Processing on a Single Image\n","\n","I'll illustrate the dataset processing workflow by performing all steps on a single image from the dataset. This demonstration showcases image preprocessing, jersey extraction , dataset creation."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T09:36:54.886872Z","iopub.status.busy":"2024-04-11T09:36:54.886087Z","iopub.status.idle":"2024-04-11T09:37:02.050359Z","shell.execute_reply":"2024-04-11T09:37:02.049358Z","shell.execute_reply.started":"2024-04-11T09:36:54.886841Z"},"trusted":true},"outputs":[],"source":["image = cv2.imread(r\"/kaggle/input/soccernet/Data/SoccerNet/jersey-2023/train/train/images/10/10_2.jpg\")\n","results = model(\"/kaggle/input/soccernet/Data/SoccerNet/jersey-2023/train/train/images/10/10_2.jpg\" , save = True)\n","keypoints = results[0].keypoints\n","# Assuming keypoints.xy is a tensor of shape (batch_size, num_keypoints, 2)\n","# Iterate over the first dimension to access each keypoint\n","for batch_idx in range(keypoints.xy.size(0)):\n","    for kpt in keypoints.xy[batch_idx]:\n","        x, y = int(kpt[0].item()), int(kpt[1].item())\n","        cv2.circle(image, (x, y), radius=3, color=(0, 255, 0), thickness=-1)\n","\n","# Display the image\n","plt.imshow(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T09:37:05.121079Z","iopub.status.busy":"2024-04-11T09:37:05.120167Z","iopub.status.idle":"2024-04-11T09:37:05.128938Z","shell.execute_reply":"2024-04-11T09:37:05.128002Z","shell.execute_reply.started":"2024-04-11T09:37:05.121045Z"},"trusted":true},"outputs":[],"source":["threshold = 0.1\n","points = []\n","\n","for kpt_data in keypoints.data[0]:\n","    # Extract the confidence (probability) of the keypoint\n","    prob = kpt_data[2].item()\n","\n","    # If the confidence is above the threshold, consider it as a valid keypoint\n","    if prob > threshold:\n","        x = kpt_data[0].item()\n","        y = kpt_data[1].item()\n","        points.append((int(x), int(y)))\n","    else:\n","        points.append(None)\n","if  keypoints.has_visible is False:\n","    points = [None] * 13\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T09:37:06.260987Z","iopub.status.busy":"2024-04-11T09:37:06.260097Z","iopub.status.idle":"2024-04-11T09:37:06.265835Z","shell.execute_reply":"2024-04-11T09:37:06.264768Z","shell.execute_reply.started":"2024-04-11T09:37:06.260936Z"},"trusted":true},"outputs":[],"source":["print(points)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T09:37:06.965938Z","iopub.status.busy":"2024-04-11T09:37:06.965257Z","iopub.status.idle":"2024-04-11T09:37:06.971605Z","shell.execute_reply":"2024-04-11T09:37:06.970646Z","shell.execute_reply.started":"2024-04-11T09:37:06.965906Z"},"trusted":true},"outputs":[],"source":["POSE_PAIRS = [(2,0),(0,1),(1,3),(4,6),(3,5),(5,6),(6,8),(5,7),(8,10),(7,9),(6,12),(5,11),(12,14),(14,16),(11,13),(13,15),(11,12),(4,2)]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T09:37:07.251116Z","iopub.status.busy":"2024-04-11T09:37:07.250159Z","iopub.status.idle":"2024-04-11T09:37:07.260317Z","shell.execute_reply":"2024-04-11T09:37:07.259307Z","shell.execute_reply.started":"2024-04-11T09:37:07.251081Z"},"trusted":true},"outputs":[],"source":["imPoints =image.copy()\n","imSkeleton= image.copy()\n","# Draw points\n","for i, p in enumerate (points):\n","\tcv2.circle(imPoints, p, 2, (255, 255,0), thickness=-1, lineType=cv2.FILLED) \n","\tcv2.putText(imPoints, \"{}\".format(i), p, cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255,0,0), 1, lineType=cv2.LINE_AA)\n","# Draw skeleton\n","for pair in POSE_PAIRS:\n","\tpartA =pair[0]\n","\tpartB =pair[1]\n","\tif points[partA] and points[partB]:\n","\t\tcv2.line(imSkeleton, points[partA], points[partB], (255, 255,0), 2) \n","\t\tcv2.circle(imSkeleton, points[partA], 2, (255, 0, 0), thickness=-1, lineType=cv2.FILLED)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T09:37:07.525692Z","iopub.status.busy":"2024-04-11T09:37:07.524785Z","iopub.status.idle":"2024-04-11T09:37:07.860074Z","shell.execute_reply":"2024-04-11T09:37:07.858872Z","shell.execute_reply.started":"2024-04-11T09:37:07.525658Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(20,20))\n","plt.subplot(121); plt.axis('off'); plt.imshow(imPoints);\n","plt.subplot(122); plt.axis('off'); plt.imshow(imSkeleton);"]},{"cell_type":"markdown","metadata":{},"source":["### Testing Workflow on a Folder of Images\n","\n","To validate the workflow, I'll apply the entire process to a folder containing multiple images. This test will assess the robustness and efficiency of the workflow across various images.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T10:19:39.864062Z","iopub.status.busy":"2024-04-11T10:19:39.863160Z","iopub.status.idle":"2024-04-11T10:19:40.299689Z","shell.execute_reply":"2024-04-11T10:19:40.298613Z","shell.execute_reply.started":"2024-04-11T10:19:39.864023Z"},"trusted":true},"outputs":[],"source":["paths = os.listdir(\"/kaggle/input/soccernet/Data/SoccerNet/jersey-2023/train/train/images/0\")\n","paths = [\"/kaggle/input/soccernet/Data/SoccerNet/jersey-2023/train/train/images/0/\"+ i for i in paths]\n","img = cv2.imread(paths[1])\n","img = cv2.resize(img , (200,200))\n","plt.imshow(img)\n","len(paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T10:19:41.845791Z","iopub.status.busy":"2024-04-11T10:19:41.844986Z","iopub.status.idle":"2024-04-11T10:20:06.607633Z","shell.execute_reply":"2024-04-11T10:20:06.606606Z","shell.execute_reply.started":"2024-04-11T10:19:41.845753Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["start_time = time.time()\n","\n","whole_numbers_generator = itertools.count(start=1)\n","# next(whole_numbers_generator)\n","npoints = 13\n","plt.figure(figsize=(200,200))\n","\n","for j in paths:\n","    print(j)\n","    image = cv2.imread(j)\n","    im_height, im_width = image.shape[:2]\n","    if image is None or im_height<75 or im_width<35:\n","        print(f\"Error: Unable to read image at index {j}. Skipping...\")\n","        continue\n","#     if im_height<180 or im_width<90:\n","    image = cv2.resize(image , (285,600))\n","    im_height, im_width = image.shape[:2]\n","    results = model(image)\n","    keypoints = results[0].keypoints\n","\n","    threshold = 0.1\n","    points = []\n","\n","    for kpt_data in keypoints.data[0]:\n","        # Extract the confidence (probability) of the keypoint\n","        prob = kpt_data[2].item()\n","\n","        # If the confidence is above the threshold, consider it as a valid keypoint\n","        if prob > threshold:\n","            x = kpt_data[0].item()\n","            y = kpt_data[1].item()\n","            points.append((int(x), int(y)))\n","        else:\n","            points.append(None)\n","    if  keypoints.has_visible is False:\n","        points = [None] * 13\n","    quadrilateral_coords = [points[6], points[5], points[12], points[11]]\n","    \n","    # Check if any of the points are None\n","    if None in quadrilateral_coords:\n","        print(f\"Error: Not enough valid points detected for image at index {j}. Skipping...\")\n","        continue\n","    x1, y1 = points[5]\n","    x2, y2 = points[6]\n","    x3, y3 = points[11]\n","    x4, y4 = points[12]\n","\n","    top = np.abs(min(y1,y2,y3,y4))\n","    left = np.abs(min(x1,x2,x3,x4))\n","    height = np.abs(max(y1,y2,y3,y4)-top)\n","    width = np.abs(max(x1,x2,x3,x4)-left)\n","    if top >= im_height*0.5 or left >= im_width*0.7:\n","        print(f\"Error: wrong player detected {j}. Skipping...\") \n","        continue\n","\n","    if 0 in [height , width , top , left]:\n","        continue\n","    img1 = image[int(top+height*.1-3):int(top+height*.8+3), int(left-10):int(left+width+10)]\n","    img1 = cv2.resize(img1 , (32 ,32))\n","    if x1 >= x2 or x1 >= x4 or x3 >= x4 or x3 >= x2 or  y1 >= y3 or y1 >=y4 or y2 >= y3 or y2 >= y4 or np.abs(x2 - x1) < 65 or np.abs(x1 - x2) < 65 :\n","        continue\n","    else:\n","        plt.subplot(50,50, next(whole_numbers_generator) )\n","        plt.axis(\"off\")\n","        plt.imshow(img1)\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print(\"Time consumed:\", elapsed_time, \"seconds\")"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T10:35:54.610134Z","iopub.status.busy":"2024-04-11T10:35:54.609151Z","iopub.status.idle":"2024-04-11T10:35:54.648073Z","shell.execute_reply":"2024-04-11T10:35:54.646909Z","shell.execute_reply.started":"2024-04-11T10:35:54.610088Z"},"trusted":true},"outputs":[],"source":["def preprocess_image(image_path):\n","    \"\"\"\n","    Preprocesses an image for jersey extraction.\n","\n","    Args:\n","        image_path (str): The path to the input image.\n","\n","    Returns:\n","        tuple or None: A tuple containing the label (\"jersey\" or \"no_jersey\") and the preprocessed image, or None if preprocessing fails.\n","    \"\"\"\n","    # Read the image\n","    image = cv2.imread(image_path)\n","    \n","    # Check if the image is valid and meets minimum size requirements\n","    if image is None or image.shape[0] < 75 or image.shape[1] < 35:\n","        return None\n","\n","    # Resize the image to a standard size\n","    image = cv2.resize(image, (285, 600))\n","\n","    # Run YOLO model on the image to detect keypoints\n","    results = model(image)\n","    keypoints = results[0].keypoints\n","    threshold = 0.1\n","    points = []\n","\n","    # Iterate through detected keypoints\n","    for kpt_data in keypoints.data[0]:\n","        # Extract the confidence (probability) of the keypoint\n","        prob = kpt_data[2].item()\n","\n","        # If the confidence is above the threshold, consider it as a valid keypoint\n","        if prob > threshold:\n","            x = kpt_data[0].item()\n","            y = kpt_data[1].item()\n","            points.append((int(x), int(y)))\n","        else:\n","            points.append(None)\n","\n","    # If no visible keypoints, return \"no_jersey\"\n","    if not keypoints.has_visible:\n","        points = [None] * 13\n","    \n","    # Extract quadrilateral coordinates\n","    quadrilateral_coords = [points[6], points[5], points[12], points[11]]\n","    \n","    # Check if any of the points are None\n","    if None in quadrilateral_coords:\n","        return None\n","        \n","    # Calculate bounding box coordinates\n","    x1, y1 = points[5]\n","    x2, y2 = points[6]\n","    x3, y3 = points[11]\n","    x4, y4 = points[12]\n","    top = np.abs(min(y1,y2,y3,y4))\n","    left = np.abs(min(x1,x2,x3,x4))\n","    height = np.abs(max(y1,y2,y3,y4)-top)\n","    width = np.abs(max(x1,x2,x3,x4)-left)\n","\n","    # Check if dimensions are valid\n","    if top >= im_height * 0.5 or left >= im_width*0.7:\n","        return None\n","    if 0 in [top, height, width, left]:\n","        return None\n","    \n","    # Extract jersey region\n","    jersey_roi = image[int(top+height*.1-3):int(top+height*.8+3), int(left-10):int(left+width+10)]\n","   \n","    try:\n","        # Resize the jersey region\n","        jersey_roi  = cv2.resize(jersey_roi  , (32 ,32))\n","    except:\n","        return None\n","    \n","    # Check if the region represents a jersey or not\n","    if x1 >= x2 or x1 >= x4 or x3 >= x4 or x3 >= x2 or  y1 >= y3 or y1 >=y4 or y2 >= y3 or y2 >= y4 or np.abs(x2 - x1) < 55 or np.abs(x1 - x2) < 55 :\n","        return [\"no_jersey\", jersey_roi]\n","    else:\n","        return [\"jersey\", jersey_roi]"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset Processing on a Folder\n","\n","To demonstrate the processing steps on the entire dataset folder, I will iterate through each image in the folder and apply the necessary operations. This will provide a comprehensive overview of the data processing pipeline.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Preparing Directories\n","\n","Ensure proper directory structure is set up for organizing processed images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T10:20:59.869770Z","iopub.status.busy":"2024-04-11T10:20:59.868906Z","iopub.status.idle":"2024-04-11T10:21:00.006119Z","shell.execute_reply":"2024-04-11T10:21:00.004936Z","shell.execute_reply.started":"2024-04-11T10:20:59.869731Z"},"trusted":true},"outputs":[],"source":["for player_id in range(len(os.listdir(\"/kaggle/input/soccernet/Data/SoccerNet/jersey-2023/train/train/images\"))):\n","    \n","    os.makedirs(\"/kaggle/working/soccernet/jersey-2023/train/train/blur_no_jersey_images/\" + str(player_id) , exist_ok=True)\n","    os.makedirs(\"/kaggle/working/soccernet/jersey-2023/train/train/images/\" + str(player_id) , exist_ok=True)\n"]},{"cell_type":"markdown","metadata":{},"source":["This code block preprocesses images from the SoccerNet dataset, separating images with jerseys and without jerseys of single folder."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T10:36:01.299223Z","iopub.status.busy":"2024-04-11T10:36:01.298463Z","iopub.status.idle":"2024-04-11T10:36:04.960186Z","shell.execute_reply":"2024-04-11T10:36:04.959124Z","shell.execute_reply.started":"2024-04-11T10:36:01.299188Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["import time\n","start_time = time.time()\n","\n","\n","for player_id_path in [\"/kaggle/input/soccernet/Data/SoccerNet/jersey-2023/train/train/images/569\"]:\n","    for frame in os.listdir(player_id_path):\n","        frame_path = os.path.join(player_id_path, frame)\n","        image = preprocess_image(frame_path)\n","        if image is not None and image[0] == \"no_jersey\":\n","            dest_path = \"/kaggle/working/soccernet/jersey-2023/train/train/blur_no_jersey_images/\" + frame_path.split(\"/\")[-2] + \"/\" + frame_path.split(\"/\")[-1]\n","            print(\"dest_path\"  , dest_path)\n","        elif image is not None and image[0] == \"jersey\":\n","            dest_path = \"/kaggle/working/soccernet/jersey-2023/train/train/images/\" + frame_path.split(\"/\")[-2] + \"/\" + frame_path.split(\"/\")[-1]\n","            print(\"dest_path\"  , dest_path)\n","        try:\n","            cv2.imwrite(dest_path, img=image[1])\n","        except Exception as e:\n","#             print(f\"Error processing image {img_path}: {str(e)}\")\n","            pass\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print(\"Time consumed:\", elapsed_time, \"seconds\")\n","print(len(os.listdir(\"/kaggle/working/soccernet/jersey-2023/train/train/images/569\")))"]},{"cell_type":"markdown","metadata":{},"source":["#### Sorting and Preparing Image Paths\n","\n","The following code block sorts and prepares the image paths for processing from the SoccerNet dataset.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T07:11:54.946239Z","iopub.status.busy":"2024-04-10T07:11:54.945827Z","iopub.status.idle":"2024-04-10T07:16:44.873528Z","shell.execute_reply":"2024-04-10T07:16:44.872643Z","shell.execute_reply.started":"2024-04-10T07:11:54.946204Z"},"trusted":true},"outputs":[],"source":["player_id_dir = os.listdir(\"/kaggle/input/soccernet/Data/SoccerNet/jersey-2023/train/train/images\")\n","player_id_dir = natsorted(player_id_dir)\n","player_id_dir = [\"/kaggle/input/soccernet/Data/SoccerNet/jersey-2023/train/train/images/\"+i+\"/\" for i in player_id_dir]\n","img_paths = [os.path.join(directory, filename) for directory in player_id_dir for filename in os.listdir(directory)]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T07:16:44.875224Z","iopub.status.busy":"2024-04-10T07:16:44.874913Z","iopub.status.idle":"2024-04-10T07:16:44.880958Z","shell.execute_reply":"2024-04-10T07:16:44.880016Z","shell.execute_reply.started":"2024-04-10T07:16:44.875199Z"},"trusted":true},"outputs":[],"source":["len(img_paths)"]},{"cell_type":"markdown","metadata":{},"source":["#### Image Processing and Saving"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T08:11:49.506166Z","iopub.status.busy":"2024-04-10T08:11:49.505784Z","iopub.status.idle":"2024-04-10T08:11:49.575279Z","shell.execute_reply":"2024-04-10T08:11:49.573968Z","shell.execute_reply.started":"2024-04-10T08:11:49.506134Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Function to process images\n","def process_and_save_image(img_path):\n","    try:\n","        image = preprocess_image(img_path)\n","        if image is not None and image[0] == \"no_jersey\":\n","            dest_path = \"/kaggle/working/soccernet/jersey-2023/train/train/blur_no_jersey_images/\" + img_path.split(\"/\")[-2] + \"/\" + img_path.split(\"/\")[-1]\n","        elif image is not None and image[0] == \"jersey\":\n","            dest_path = \"/kaggle/working/soccernet/jersey-2023/train/train/images/\" + img_path.split(\"/\")[-2] + \"/\" + img_path.split(\"/\")[-1]\n","        cv2.imwrite(dest_path, img=image[1])\n","    except Exception as e:\n","        print(f\"Error processing image {img_path}: {str(e)}\")\n","        pass\n","\n","# Main function\n","def main():\n","    start_time = time.time()\n","    \n","    with concurrent.futures.ThreadPoolExecutor() as executor:\n","        executor.map(process_and_save_image, img_paths)\n","\n","    end_time = time.time()\n","    elapsed_time = end_time - start_time\n","    print(\"Time consumed:\", elapsed_time, \"seconds\")\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"markdown","metadata":{},"source":["## Data Creation Procedure\n","\n","### Preprocessing and Function Implementation\n","1. **Preprocessing Steps:** Initially, complete the preprocessing steps required for the image extraction and processing tasks.\n","2. **Function Implementation:** Implement necessary functions for image extraction and processing to facilitate subsequent steps.\n","\n","### Grouping Extracted Jersey Numbers\n","1. **Reading Ground Truth JSON File:**\n","```python\n","   with open(r'Data\\SoccerNet\\jersey-2023\\test\\test\\test_gt.json', 'r') as file:\n","       data = json.load(file)\n","```\n","2. **Defining Labels and Paths:**\n","```python\n","    labels = []\n","    paths = []\n","    for i in range(len(data)):\n","        for j in os.listdir(path_to_preprocessed_extracted_jersey_no_images + str(i)+\"/\"):\n","            label = data[str(i)]\n","            path = path_to_preprocessed_extracted_jersey_no_images + str(i)+\"/\"+j\n","            labels.append(label)\n","            paths.append(path)\n","```\n","3. **Creating DataFrame:**\n","```python\n","    df = pd.DataFrame({\"img_path\": paths, \"label\": labels})\n","```\n","\n","4. **Sorting DataFrame by Label:**\n","```python\n","    grouped = df.sort_values(by=['label'])\n","```\n","5. **Creating Directories for Data Storage:**\n","```python\n","    unique_labels = list(set(data.values()))\n","    for label in unique_labels:\n","        os.makedirs(\"test/test/images/\" + str(label), exist_ok=True)\n","```\n","6. **Grouping Jersey Extracts with Corresponding Labels:**\n","```python\n","    for _, row in grouped.iterrows():\n","        label = row[\"label\"]\n","        source = row[\"img_path\"]\n","        destination = \"test/test/images/\" + str(label) + \"/\"\n","        try:\n","            shutil.copy(source, destination)\n","            print(\"File copied successfully.\")\n","        except shutil.SameFileError:\n","            print(\"Source and destination represent the same file.\")\n","        except PermissionError:\n","            print(\"Permission denied.\")\n","        except Exception as e:\n","            print(f\"Error occurred while copying file: {e}\")\n","```\n","### Manual Data Cleaning\n","* After the initial data organization step, manual data cleaning was conducted.\n","* Each extracted image was carefully inspected to remove any erroneous or irrelevant samples.\n","* The cleaning process ensured that only high-quality and relevant data remained for further analysis and model training.\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4619900,"sourceId":7873145,"sourceType":"datasetVersion"},{"datasetId":4637109,"sourceId":7896693,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
